{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0901a2f9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-07T20:09:18.438381Z",
     "iopub.status.busy": "2025-10-07T20:09:18.438190Z",
     "iopub.status.idle": "2025-10-07T20:09:19.473996Z",
     "shell.execute_reply": "2025-10-07T20:09:19.473161Z"
    },
    "papermill": {
     "duration": 1.041175,
     "end_time": "2025-10-07T20:09:19.475408",
     "exception": false,
     "start_time": "2025-10-07T20:09:18.434233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100 1124k  100 1124k    0     0  1642k      0 --:--:-- --:--:-- --:--:-- 1642k\r\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://www.gutenberg.org/files/1268/1268-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771b16ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T20:09:19.482395Z",
     "iopub.status.busy": "2025-10-07T20:09:19.481845Z",
     "iopub.status.idle": "2025-10-07T20:09:26.383385Z",
     "shell.execute_reply": "2025-10-07T20:09:26.382550Z"
    },
    "papermill": {
     "duration": 6.906213,
     "end_time": "2025-10-07T20:09:26.384711",
     "exception": false,
     "start_time": "2025-10-07T20:09:19.478498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b7e2d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T20:09:26.391830Z",
     "iopub.status.busy": "2025-10-07T20:09:26.391083Z",
     "iopub.status.idle": "2025-10-07T20:09:26.416239Z",
     "shell.execute_reply": "2025-10-07T20:09:26.415658Z"
    },
    "papermill": {
     "duration": 0.029508,
     "end_time": "2025-10-07T20:09:26.417177",
     "exception": false,
     "start_time": "2025-10-07T20:09:26.387669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length: 1112310\n",
      "Unique Characters: 80\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('1268-0.txt', 'r', encoding=\"utf8\") as fp:\n",
    "    text=fp.read()\n",
    "\n",
    "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "text = text[start_indx:end_indx]\n",
    "char_set = set(text)\n",
    "\n",
    "print('Total Length:', len(text))\n",
    "print('Unique Characters:', len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4d5d73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T20:09:26.423359Z",
     "iopub.status.busy": "2025-10-07T20:09:26.422919Z",
     "iopub.status.idle": "2025-10-07T20:09:26.541217Z",
     "shell.execute_reply": "2025-10-07T20:09:26.540453Z"
    },
    "papermill": {
     "duration": 0.122539,
     "end_time": "2025-10-07T20:09:26.542356",
     "exception": false,
     "start_time": "2025-10-07T20:09:26.419817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MYSTERIOUS  == Encoding ==> [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
      "[33 43 36 25 38 28] == Reverse ==> ISLAND\n",
      "44 -> T\n",
      "32 -> H\n",
      "29 -> E\n",
      "1 ->  \n",
      "37 -> M\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)} # e.g {\"a\": 2}\n",
    "char_array = np.array(chars_sorted)\n",
    "text_encoded = np.array([char2int[ch] for ch in text], dtype=np.int32)\n",
    "\n",
    "print(text[:15], '== Encoding ==>', text_encoded[:15])\n",
    "print(text_encoded[15:21], '== Reverse ==>',''.join(char_array[text_encoded[15:21]]))\n",
    "for ex in text_encoded[:5]:\n",
    "    print('{} -> {}'.format(ex, char_array[ex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f37e307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T20:09:26.549727Z",
     "iopub.status.busy": "2025-10-07T20:09:26.549116Z",
     "iopub.status.idle": "2025-10-07T20:09:26.901733Z",
     "shell.execute_reply": "2025-10-07T20:09:26.901109Z"
    },
    "papermill": {
     "duration": 0.357426,
     "end_time": "2025-10-07T20:09:26.903008",
     "exception": false,
     "start_time": "2025-10-07T20:09:26.545582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "def create_text_chunks(text_encoded, chunk_size): \n",
    "    \"\"\" Create overlapping chunks from encoded text.\n",
    "        Example\n",
    "        text_encoded = [1, 2, 3, 4, 5, 6, 7], chunk_size = 4\n",
    "        Chunk 0: [1, 2, 3, 4]  (positions 0-3)\n",
    "        Chunk 1: [2, 3, 4, 5]  (positions 1-4)\n",
    "        Chunk 2: [3, 4, 5, 6]  (positions 2-5)\n",
    "        Chunk 3: [4, 5, 6, 7]  (positions 3-6)\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(len(text_encoded) - chunk_size + 1):\n",
    "        chunk = text_encoded[i:i + chunk_size]\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "text_chunks = create_text_chunks(text_encoded, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b66ff0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T20:09:26.909894Z",
     "iopub.status.busy": "2025-10-07T20:09:26.909660Z",
     "iopub.status.idle": "2025-10-07T20:09:26.913814Z",
     "shell.execute_reply": "2025-10-07T20:09:26.913303Z"
    },
    "papermill": {
     "duration": 0.008815,
     "end_time": "2025-10-07T20:09:26.914908",
     "exception": false,
     "start_time": "2025-10-07T20:09:26.906093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_chunk = self.text_chunks[idx]\n",
    "        return text_chunk[:-1].long(), text_chunk[1:].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff4f37a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T20:09:26.920928Z",
     "iopub.status.busy": "2025-10-07T20:09:26.920710Z",
     "iopub.status.idle": "2025-10-07T20:09:34.271053Z",
     "shell.execute_reply": "2025-10-07T20:09:34.270156Z"
    },
    "papermill": {
     "duration": 7.354641,
     "end_time": "2025-10-07T20:09:34.272217",
     "exception": false,
     "start_time": "2025-10-07T20:09:26.917576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (x):  'THE MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n1'\n",
      "Target (y):  'HE MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n18'\n",
      "\n",
      "Input (x):  'HE MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n18'\n",
      "Target (y):  'E MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n187'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20/3395361760.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  seq_dataset = TextDataset(torch.tensor(text_chunks))\n"
     ]
    }
   ],
   "source": [
    "seq_dataset = TextDataset(torch.tensor(text_chunks))\n",
    "\n",
    "for i, (input_token, output_token) in enumerate(seq_dataset):\n",
    "    print('Input (x): ', repr(''.join(char_array[input_token])))\n",
    "    print('Target (y): ', repr(''.join(char_array[output_token])))\n",
    "    print()\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b13dfc70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T20:09:34.278910Z",
     "iopub.status.busy": "2025-10-07T20:09:34.278703Z",
     "iopub.status.idle": "2025-10-07T20:09:34.289878Z",
     "shell.execute_reply": "2025-10-07T20:09:34.289358Z"
    },
    "papermill": {
     "duration": 0.015648,
     "end_time": "2025-10-07T20:09:34.291011",
     "exception": false,
     "start_time": "2025-10-07T20:09:34.275363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "seq_dl = DataLoader(seq_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "332422fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T20:09:34.297282Z",
     "iopub.status.busy": "2025-10-07T20:09:34.297085Z",
     "iopub.status.idle": "2025-10-07T20:09:34.302165Z",
     "shell.execute_reply": "2025-10-07T20:09:34.301663Z"
    },
    "papermill": {
     "duration": 0.009321,
     "end_time": "2025-10-07T20:09:34.303141",
     "exception": false,
     "start_time": "2025-10-07T20:09:34.293820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, charset_size, embed_dim, rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.embedding = nn.Embedding(charset_size, embed_dim)\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size,batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, charset_size)\n",
    "    \n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x).unsqueeze(1)  # [batch, embed] -> [batch, 1, embed] for RNN\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell)) # each char is depended on prev, so we need to pass the hidden and cell here\n",
    "        out = self.fc(out).reshape(out.size(0), -1) # we need to reshape because we add 1 more dim in the beginning\n",
    "        return out, hidden, cell\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # (num_layers * num_directions(1 if uni, 2 if bi), batch_size, hidden_size)\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2637862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T20:09:34.309354Z",
     "iopub.status.busy": "2025-10-07T20:09:34.309159Z",
     "iopub.status.idle": "2025-10-07T20:09:34.709025Z",
     "shell.execute_reply": "2025-10-07T20:09:34.708349Z"
    },
    "papermill": {
     "duration": 0.404066,
     "end_time": "2025-10-07T20:09:34.710137",
     "exception": false,
     "start_time": "2025-10-07T20:09:34.306071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(80, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=80, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charset_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "torch.manual_seed(1)\n",
    "model = RNN(charset_size, embed_dim, rnn_hidden_size)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1a1b1b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T20:09:34.717330Z",
     "iopub.status.busy": "2025-10-07T20:09:34.716906Z",
     "iopub.status.idle": "2025-10-07T20:09:40.492448Z",
     "shell.execute_reply": "2025-10-07T20:09:40.491871Z"
    },
    "papermill": {
     "duration": 5.780631,
     "end_time": "2025-10-07T20:09:40.493948",
     "exception": false,
     "start_time": "2025-10-07T20:09:34.713317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02770c69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T20:09:40.501340Z",
     "iopub.status.busy": "2025-10-07T20:09:40.500673Z",
     "iopub.status.idle": "2025-10-07T20:29:32.565243Z",
     "shell.execute_reply": "2025-10-07T20:29:32.564588Z"
    },
    "papermill": {
     "duration": 1192.069492,
     "end_time": "2025-10-07T20:29:32.566711",
     "exception": false,
     "start_time": "2025-10-07T20:09:40.497219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:09:41] Epoch 0 loss: 4.3712\n",
      "[20:10:41] Epoch 500 loss: 1.5249\n",
      "[20:11:40] Epoch 1000 loss: 1.4125\n",
      "[20:12:40] Epoch 1500 loss: 1.3283\n",
      "[20:13:39] Epoch 2000 loss: 1.2046\n",
      "[20:14:38] Epoch 2500 loss: 1.1970\n",
      "[20:15:38] Epoch 3000 loss: 1.1570\n",
      "[20:16:38] Epoch 3500 loss: 1.1746\n",
      "[20:17:37] Epoch 4000 loss: 1.1341\n",
      "[20:18:37] Epoch 4500 loss: 1.0954\n",
      "[20:19:36] Epoch 5000 loss: 1.1228\n",
      "[20:20:36] Epoch 5500 loss: 1.0735\n",
      "[20:21:35] Epoch 6000 loss: 1.0659\n",
      "[20:22:35] Epoch 6500 loss: 1.0894\n",
      "[20:23:35] Epoch 7000 loss: 1.0446\n",
      "[20:24:34] Epoch 7500 loss: 1.1123\n",
      "[20:25:34] Epoch 8000 loss: 1.1016\n",
      "[20:26:34] Epoch 8500 loss: 1.0806\n",
      "[20:27:33] Epoch 9000 loss: 0.9845\n",
      "[20:28:33] Epoch 9500 loss: 1.0307\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 10000\n",
    "torch.manual_seed(1)\n",
    "for epoch in range(num_epochs):\n",
    "    for seq_batch, target_batch in seq_dl: # seq_batch.size() -> (64, 40)\n",
    "        # Move data to GPU\n",
    "        seq_batch = seq_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "        \n",
    "        hidden, cell = model.init_hidden(batch_size)\n",
    "        hidden = hidden.to(device)\n",
    "        cell = cell.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0\n",
    "        \n",
    "        for c in range(seq_length):\n",
    "            pred, hidden, cell = model(seq_batch[:, c], hidden, cell)\n",
    "            loss += loss_fn(pred, target_batch[:, c])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.item()/seq_length\n",
    "\n",
    "        if epoch % 500 == 0:\n",
    "            current_time = time.strftime(\"%H:%M:%S\")\n",
    "            print(f'[{current_time}] Epoch {epoch} loss: {loss:.4f}')\n",
    "\n",
    "        break # we just do 1 iteration here because the sheer number of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10f41d70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T20:29:32.575767Z",
     "iopub.status.busy": "2025-10-07T20:29:32.575190Z",
     "iopub.status.idle": "2025-10-07T20:29:32.581096Z",
     "shell.execute_reply": "2025-10-07T20:29:32.580536Z"
    },
    "papermill": {
     "duration": 0.011263,
     "end_time": "2025-10-07T20:29:32.582139",
     "exception": false,
     "start_time": "2025-10-07T20:29:32.570876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "def sample(model, starting_str, len_generated_text=500, scale_factor=1.0):\n",
    "    encoded_input = torch.tensor([char2int[s] for s in starting_str])\n",
    "    encoded_input = torch.reshape(encoded_input, (1, -1)) # add batch dim\n",
    "    encoded_input =encoded_input.to(device)\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.eval()\n",
    "    hidden, cell = model.init_hidden(1)\n",
    "    hidden = hidden.to(device)\n",
    "    cell = cell.to(device)\n",
    "    \n",
    "    for c in range(len(starting_str)-1): # we want to start the generation with last char, so we omit it here\n",
    "        # _, hidden, cell = model(encoded_input[:, c].view(1), hidden, cell)\n",
    "        _, hidden, cell = model(encoded_input[:, c], hidden, cell)\n",
    "\n",
    "    last_char = encoded_input[:, -1]\n",
    "\n",
    "    for i in range(len_generated_text):\n",
    "        \n",
    "        logits, hidden, cell = model(last_char.view(1).to(device), hidden, cell)\n",
    "        logits = torch.squeeze(logits, 0)\n",
    "        scaled_logits = logits * scale_factor\n",
    "        m = Categorical(logits=scaled_logits)\n",
    "        last_char = m.sample()\n",
    "        generated_str += str(char_array[last_char])\n",
    "\n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b0ca1c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T20:29:32.590211Z",
     "iopub.status.busy": "2025-10-07T20:29:32.589810Z",
     "iopub.status.idle": "2025-10-07T20:29:34.523530Z",
     "shell.execute_reply": "2025-10-07T20:29:34.522645Z"
    },
    "papermill": {
     "duration": 1.939146,
     "end_time": "2025-10-07T20:29:34.524836",
     "exception": false,
     "start_time": "2025-10-07T20:29:32.585690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Scale factor 0.5 ==\n",
      "The island\n",
      "bore, Abold thwerm.\n",
      "Or countened “FaY ismblu’s’ down, and,\n",
      "already, if tremendou? Might clmativy,--W1\n",
      "In a wry Nave!” “J*rnh Gzebbvellience came which was, I will, not\n",
      "even’t xagumous animyie.”\n",
      "\n",
      "ToLPocht wih numberlscat, but ojeoward Lown a\n",
      "great.\n",
      "It was, esseithard, a\n",
      "Bible, surre!-Linally Turlacpkings aid.\n",
      "\n",
      "Yef.\n",
      "Hopels, TomwIred, planimation fell no\n",
      "coverak.\n",
      "\n",
      "This last penfect of\n",
      "Ameyouse, ‘perhausiz was yellow unheadvelt,-, acquaignm, wxiden,\n",
      "reign. Speparet unexpicially so unfortufe.\n",
      "\n",
      "Othin\n",
      "\n",
      "\n",
      "== Scale factor 1.0 ==\n",
      "The island in the\n",
      "open aix and the sailor’s idea was rounds, and opened by Top’s blood.\n",
      "\n",
      "When Cyrus Harding and Spilett, Herbert, and Neb, having so complished without difficulty! Their engineer, formed by the winter grunts of notice.\n",
      "\n",
      "They believed, the larder was still reply.\n",
      "\n",
      "“Perhaps the passage of nine oyster; that, Mr. Herbert.”\n",
      "\n",
      "“Judge so Shark youn form a desirious and two miles off the bank after the island. The Fer sailor snow.\n",
      "\n",
      "But on the 20th of Aprility of Granite House, and the waves spread \n",
      "\n",
      "\n",
      "== Scale factor 2.0 ==\n",
      "The island was not an hour, as was a great part of the colony,\n",
      "for the settlers were finished. They were extended on the storerooms of the river and a master in the basalts. The reporter’s arms under the seaman would not be so companions would be as much astonished the waves which resist the sailor’s\n",
      "ear, and in the morning the reporter and Pencroft had not asked them on the sand. The boat of the lake was now to be feared that the storeroom would be a man, who was becoming round one of the storeroom, as w\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "scale_factors = [.5, 1., 2.]\n",
    "starting_str='The island'\n",
    "\n",
    "for scale_factor in scale_factors:\n",
    "    print(f'== Scale factor {scale_factor} ==')\n",
    "    print(sample(model, starting_str = 'The island', scale_factor=scale_factor))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533165b7",
   "metadata": {
    "papermill": {
     "duration": 0.003626,
     "end_time": "2025-10-07T20:29:34.532626",
     "exception": false,
     "start_time": "2025-10-07T20:29:34.529000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1224.031522,
   "end_time": "2025-10-07T20:29:37.335502",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-07T20:09:13.303980",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
